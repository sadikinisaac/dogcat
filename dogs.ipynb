{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                 # working with, mainly resizing, images\n",
    "import numpy as np         # dealing with arrays\n",
    "import os                  # dealing with directories\n",
    "from random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'C:/Users/Isaac Sadikin/Desktop/AI/dogs/train'\n",
    "TEST_DIR = 'C:/Users/Isaac Sadikin/Desktop/AI/dogs/test'\n",
    "IMG_SIZE = 50\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '2conv-basic')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    word_label = img.split('.')[-3]\n",
    "    # conversion to one-hot array [cat,dog]\n",
    "    #                            [much cat, no dog]\n",
    "    if word_label == 'cat': return [1,0]\n",
    "    #                             [no cat, very doggo]\n",
    "    elif word_label == 'dog': return [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([np.array(img),np.array(label)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR,img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "        \n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [06:18<00:00, 66.07it/s] \n"
     ]
    }
   ],
   "source": [
    "train_data = create_train_data()\n",
    "# If you have already created the dataset:\n",
    "#train_data = np.load('train_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-73cc10018a95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_pool_2d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfully_connected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mregression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tflearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_training_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tflearn\\config.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6d61acecdded>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}.meta'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model loaded!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-6d5f57832cc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "train = train_data[:-500]\n",
    "test = train_data[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-cadeb69fedfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-b430ddc3e5f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.fit({'input': X}, {'targets': Y}, n_epoch=3, validation_set=({'input': test_x}, {'targets': test_y}), \n\u001b[0m\u001b[0;32m      2\u001b[0m     snapshot_step=500, show_metric=True, run_id=MODEL_NAME)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit({'input': X}, {'targets': Y}, n_epoch=3, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-fb54ebdb96f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mconvnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconvnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')\n",
    "\n",
    "train = train_data[:-500]\n",
    "test = train_data[-500:]\n",
    "\n",
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test]\n",
    "\n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch=3, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-1476cbdb4d13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# import module we'll need to import our custom module\n",
    "from shutil import copyfile\n",
    "\n",
    "# copy our file into the working directory (make sure it has .py suffix)\n",
    "copyfile(src = \"../input/view-class/view_helper.py\", dst = \"../working/view_helper.py\")\n",
    "\n",
    "# import all our functions\n",
    "import view_helper as helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"../input/dogs-vs-cats-for-pytorch/cat_dog_data/Cat_Dog_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../input/dogs-vs-cats-for-pytorch/cat_dog_data/Cat_Dog_data'\n",
    "\n",
    "# TODO: Define transforms for the training data and testing data\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(224),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-f4589e995e3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# change this to the trainloader or testloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "# change this to the trainloader or testloader \n",
    "data_iter = iter(trainloader)\n",
    "\n",
    "images, labels = next(data_iter)\n",
    "fig, axes = plt.subplots(figsize=(10,10), ncols=4)\n",
    "for ii in range(4):\n",
    "    ax = axes[ii]\n",
    "    helper.imshow(images[ii], ax=ax, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-fd6f92bdfd96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-b2e6e4793e04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# import module we'll need to import our custom module\n",
    "from shutil import copyfile\n",
    "\n",
    "# copy our file into the working directory (make sure it has .py suffix)\n",
    "copyfile(src = \"../input/view-class/view_helper.py\", dst = \"../working/view_helper.py\")\n",
    "\n",
    "# import all our functions\n",
    "import view_helper as helper\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'PetImages/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-bf726fcdf674>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Create training folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Moves all training cat images to cats folder, training dog images to dogs folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'PetImages/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "base_dir = \"PetImages/\"\n",
    "\n",
    "# Create training folder\n",
    "files = os.listdir(base_dir)\n",
    "\n",
    "# Moves all training cat images to cats folder, training dog images to dogs folder\n",
    "def train_maker(name):\n",
    "  train_dir = f\"{base_dir}/train/{name}\"\n",
    "  for f in files:\n",
    "        search_object = re.search(name, f)\n",
    "        if search_object:\n",
    "          shutil.move(f'{base_dir}/{name}', train_dir)\n",
    "\n",
    "train_maker(\"Cat\")\n",
    "train_maker(\"Dog\")\n",
    "\n",
    "# Make the validation directories\n",
    "try:\n",
    "    os.makedirs(\"val/Cat\")\n",
    "    os.makedirs(\"val/Dog\")\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\")\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \")\n",
    "\n",
    "# Create validation folder\n",
    "\n",
    "cat_train = base_dir + \"train/Cat/\"\n",
    "cat_val = base_dir + \"val/Cat/\"\n",
    "dog_train = base_dir + \"train/Dog/\"\n",
    "dog_val = base_dir + \"val/Dog/\"\n",
    "\n",
    "cat_files = os.listdir(cat_train)\n",
    "dog_files = os.listdir(dog_train)\n",
    "\n",
    "# This will put 1000 images from the two training folders\n",
    "# into their respective validation folders\n",
    "\n",
    "for f in cat_files:\n",
    "    validationCatsSearchObj = re.search(\"5\\d\\d\\d\", f)\n",
    "    if validationCatsSearchObj:\n",
    "        shutil.move(f'{cat_train}/{f}', cat_val)\n",
    "\n",
    "for f in dog_files:\n",
    "    validationCatsSearchObj = re.search(\"5\\d\\d\\d\", f)\n",
    "    if validationCatsSearchObj:\n",
    "        shutil.move(f'{dog_train}/{f}', dog_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-064f8043938a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-40-0dd36f5be17a>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-40-0dd36f5be17a>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    transform = transforms.Compose([transforms.CenterCrop(224), transforms.ToTensor())\u001b[0m\n\u001b[1;37m                                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "folder_path = \"/Users/krshrimali/Documents/dataset/train/\"\n",
    "transform = transforms.Compose([transforms.CenterCrop(224), transforms.ToTensor())\n",
    "data = datasets.ImageFolder(root = os.path.join(folder_path), transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-39f1566c619b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# Imports here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class DogsVSCats():\n",
    "    IMG_SIZE = 50\n",
    "    CATS = \"C:/Users/Isaac Sadikin/Desktop/AI/dogcat/PetImages/Cat\"\n",
    "    DOGS = \"C:/Users/Isaac Sadikin/Desktop/AI/dogcat/PetImages/Dog\"\n",
    "    TESTING = \"PetImages/Testing\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogsVSCats():\n",
    "    IMG_SIZE = 50\n",
    "    CATS = \"C:/Users/Isaac Sadikin/Desktop/AI/dogcat/PetImages/Cat\"\n",
    "    DOGS = \"C:/Users/Isaac Sadikin/Desktop/AI/dogcat/PetImages/Dog\"\n",
    "    TESTING = \"PetImages/Testing\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "\n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                if \"jpg\" in f:\n",
    "                    try:\n",
    "                        pass\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                        #print(label, f, str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DogsVSCats():\n",
    "    IMG_SIZE = 50\n",
    "    CATS = \"C:/Users/Isaac Sadikin/Desktop/AI/dogcat/PetImages/Cat\"\n",
    "    DOGS = \"C:/Users/Isaac Sadikin/Desktop/AI/dogcat/PetImages/Dog\"\n",
    "    TESTING = \"PetImages/Testing\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "\n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                if \"jpg\" in f:\n",
    "                    try:\n",
    "                        path = os.path.join(label, f)\n",
    "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "                        self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot \n",
    "                        #print(np.eye(2)[self.LABELS[label]])\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                        #print(label, f, str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Isaac Sadikin/Desktop/AI/dogcat/PetImages/Cat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12501/12501 [01:22<00:00, 152.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Isaac Sadikin/Desktop/AI/dogcat/PetImages/Dog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12501/12501 [01:17<00:00, 160.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cats: 12476\n",
      "Dogs: 12470\n"
     ]
    }
   ],
   "source": [
    "REBUILD_DATA = True # set to true to one once, then back to false unless you want to change something in your training data.\n",
    "\n",
    "class DogsVSCats():\n",
    "    IMG_SIZE = 50\n",
    "    CATS = \"C:/Users/Isaac Sadikin/Desktop/AI/dogcat/PetImages/Cat\"\n",
    "    DOGS = \"C:/Users/Isaac Sadikin/Desktop/AI/dogcat/PetImages/Dog\"\n",
    "    TESTING = \"PetImages/Testing\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "\n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                if \"jpg\" in f:\n",
    "                    try:\n",
    "                        path = os.path.join(label, f)\n",
    "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "                        self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot \n",
    "                        #print(np.eye(2)[self.LABELS[label]])\n",
    "\n",
    "                        if label == self.CATS:\n",
    "                            self.catcount += 1\n",
    "                        elif label == self.DOGS:\n",
    "                            self.dogcount += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                        #print(label, f, str(e))\n",
    "\n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print('Cats:',dogsvcats.catcount)\n",
    "        print('Dogs:',dogsvcats.dogcount)\n",
    "\n",
    "if REBUILD_DATA:\n",
    "    dogsvcats = DogsVSCats()\n",
    "    dogsvcats.make_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24946\n"
     ]
    }
   ],
   "source": [
    "training_data = np.load(\"training_data.npy\", allow_pickle=True)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
    "X = X/255.0\n",
    "y = torch.Tensor([i[1] for i in training_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xad896d5648>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xad8976b8c8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[50], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
